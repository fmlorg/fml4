.C	WWW 関係 (HyperReference ...)
.l	href
.key	WWW
.k	ローカルスプールへのftp操作
.key	localftp
.key	http://
.key	gopher://
.key	ftp://


.S	自動的に スプールを html 化する(Expireはしない)
.l	SyncHtml
.key	自動 html 化
.key	libsynchtml.pl
.xref	spool2html.pl

fml.pl の中から外部の SyncHTMLfiles.pl を呼んでやらせるのは美しくない
ので;-)、HOOK でやれるように書き直しました。
注意： libsynchtml.pl により SyncHtml.pl は Obsolete になりました

SYNOPSIS:
	&SyncHtml(生成されたHTMLを置く場所, $ID, *Envelope);

	$ID		記事番号は &Distribute; で
			グローバル変数 $ID はセットされる。
	*Envelope	Envelope

例：
	$FML_EXIT_HOOK .= q#;
		&use('synchtml');
		$HTTP_DIR = 'var/htdocs';
		&SyncHtml($HTTP_DIR, $ID, *Envelope);
	#;

	var/htdocs/index.html 
	var/htdocs/記事番号.html 

を生成します。index.html の中身は

	<LI>
	<A HREF=1310.html>
	96/09/16 18:12:33 Subject
	</A>

のような

	<UL>
	…
	<LI> <A HREF=記事番号.html> Summary ファイルもどき </A>
	…

構造を自動的に作ります。

$HTML_INDEX_REVERSE_ORDER がセットされていると逆方向に <LI> エントリを
作ります。つまり新しい記事が最初に来るわけです。
.k	$HTML_INDEX_REVERSE_ORDER

この時各 directory の .indexcache にキャッシュされているデータから生成
しています。ファイル .indexcache は $HTML_DATA_CACHE で変更できます。
.k	$HTML_DATA_CACHE


コマンドラインからのためのインターフェイスに spool2html.pl というのも
あります。
.xref spool2html.pl


.S	HTML化するUNIT (数 or 日)
.l	$HTML_INDEX_UNIT
.key	$HTML_INDEX_UNIT

	$HTML_INDEX_UNIT (default 'day') 

expireしない場合一つの var/htdocs/ に数千のファイルができることになり
かねません。これよりはファイル１００個ごと、もしくは日ごとにdirectory
をまとめておく方が見やすいでしょう。

現在の標準実装のデフォールトは $HTML_INDEX_UNIT = 'day'; で

	var/htdocs/19960916/index.html
	var/htdocs/19960916/記事番号.html
	…

のように 1996/09/16 日のＭＬの記事を var/htdocs/19960916/ 以下にHTML化
します。

また、
	$HTML_INDEX_UNIT = 数字 (e.g. 100)

とした場合記事１００個ごとに別のdirectoryを作ります。
  
	var/htdocs/100/
	var/htdocs/200/
	…

.S	HTMLファイルのExpire
.k	$HTML_EXPIRE

$HTML_EXPIRE	(default 0)
	expire の“日”数。もし０以下ならおこなわない。
	これが指定されていないときは index.html は増える一方:-)


.S	BASE64の展開
.k	$BASE64_DECODE
.k	mewdecode

base64 で encode されたものがあった場合$BASE64_DECODE という変数に定義
された base64 decoder を使って展開しその結果をHTMLの中に埋め込みます。
なお展開した結果はfmlが勝手につけた名前でファイルに落されます。
ユーザが与えた名前は security 上使いません。

例：
	BASE64_DECODE = "/usr/local/bin/mewdecode";


.S	$HTML_OUTPUT_FILTER
.k	$HTML_OUTPUT_FILTER

index.html を作る時 $HTML_OUTPUT_FILTER というプログラムを通してから作
る。具体的には 日本語漢字変換やMIME,BASE64 decoder 等が該当するだろう。


.S	$HTML_TITLE_HOOK
.k	$HTML_TITLE_HOOK

HTMLに変換された記事をファイルに保存する直前に実行されるフック。

例：
	q#$HtmlTitle = sprintf("%s %s", $Now, $HtmlTitle);#;

で、タイトルのシンタックスを日付を付け加える等…変えられる。


.S	キーワードによるHTML化の自動分類 （今の実装でOKか未確認？）
.k	@HTML_FIELD
.k	Keyword:

ヘッダの Keyword: エントリが含んでいるキーワードが @HTML_FIELD のどれ
かにマッチした場合に、キーワード別に別のHTML階層を作ります。



.S	TalkWithHttpServer
.l	TalkWithHttpServer
.k	TalkWithHttpServer
.k	&TalkWithHttpServer
.xref	geturl.pl

SYNOPSIS:
	&TalkWithHttpServer($host, $port, $request, $tp, *e); 

	$host		ホスト		(e.g. www.iij.ad.jp)
	$port		ポート番号	(70, 80, 21, ...)
	$request	リクエストの内容
	$tp		TYPE OF PROTOCOL (http, gopher, ftp, ...)
	*e		答えを入れるためのstab

例：
    if ($tp =~ /http/i) {
	$host = $host || $DEFAULT_HTTP_SERVER;
	$port = $port || $DEFAULT_HTTP_PORT || 80;

	# connect http server
	&Mesg(*e, ">>> HREF=$tp://$host$request\n");
	&TalkWithHttpServer($host, $port, $request, $tp, *e); 
	&Mesg(*e, ">>> ENDS HREF=$tp://$host$request\n");
    } 
	

.S	URLの中身を返すサーバ
.k	&HRef(...)
.k	libhref.pl

一番単純なやり方は

$START_HOOK = q#
    require 'libhref.pl';
    &HRef($Envelope{'Body'}, *Envelope);
    $DO_NOTHING =1;
#;

です。こうするとメール本文をコマンドレポートの形で送り返します。


.S	HRef関数によるURL先データの引き落とし
.l	HRef
.k	&HRef
.k	HRef


    &HRef($request, *Envelope);

$request のURLの内容を$Envelope{'message'}に入れて送り返す。
$request は

	http://
	gopher://
	ftp://

を理解します。ftp はローカル or ftpmailへのリレーへ自動的に切替えます。
また、もしバイナリデータの場合はuuencodeして送り返します。


.# $Id$
.# Copyright (C) 1993-1996 fukachan@phys.titech.ac.jp
.# Copyright (C) 1996      fukachan@sapporo.iij.ad.jp
.# fml is free software distributed under the terms of the GNU General
.# Public License. see the file COPYING for more details.
