.C	WWW 関係 (HyperReference ...)
.l	href
.k	WWW
.k	ローカルスプールへのftp操作


注意: HTML を作る場所ですが、デフォールトでは var/htdocs -> htdocs/ に
変わっています。var は nobody 等へpermission を出していないからです。


.S	自動的に スプールを html 化する(Expireはしない)
.l	SyncHtml
.key	自動 html 化
.key	libsynchtml.pl
.xref	spool2html.pl
.k	$AUTO_HTML_GEN

$AUTO_HTML_GEN = 1; をセットすると、自動的にHTML化された記事も作ります。
この時普通のPLAINTEXTのスプール($SPOOL_DIRへ溜る)も同時に作っています。
HTML化は全く別のプロセスです。スプールに関しては何もしません。
必要ならスプールのEXPIRE等は別途明示的に設定する必要があります。
.xref	expire

HTML化の実体は HOOK で呼び出されます。
fml.pl の中から外部の SyncHTMLfiles.pl を呼んでやらせるのは美しくない
ので;-)、HOOK でやれるように書き直しました。
注意: libsynchtml.pl により SyncHtml.pl は obsolete になりました

SYNOPSIS:
	&SyncHtml(生成されたHTMLを置く場所, $ID, *Envelope);
.k	&SyncHtml

	$ID		記事番号は &Distribute; で
			グローバル変数 $ID はセットされる。
	*Envelope	Envelope

例：
	$FML_EXIT_HOOK .= q#;
		&use('synchtml');
		$HTTP_DIR = 'htdocs';
		&SyncHtml($HTTP_DIR, $ID, *Envelope);
	#;

	htdocs/index.html 
	htdocs/記事番号.html 

を生成します。index.html の中身は

	<LI>
	<A HREF=1310.html>
	96/09/16 18:12:33 Subject
	</A>

のような

	<UL>
	…
	<LI> <A HREF=記事番号.html> Summary ファイルもどき </A>
	…

構造を自動的に作ります。

$HTML_INDEX_REVERSE_ORDER がセットされていると逆方向に <LI> エントリを
作ります。つまり新しい記事が最初に来るわけです。
.k	$HTML_INDEX_REVERSE_ORDER

この時各 directory の .indexcache にキャッシュされているデータから生成
しています。ファイル .indexcache は $HTML_DATA_CACHE で変更できます。
.k	$HTML_DATA_CACHE

また、スレッドを生成するためのキャッシュのファイル名は 
$HTML_DATA_THREAD です。
.k	$HTML_DATA_THREAD


同じライブラリを呼んで同じことをするコマンドラインからのためのインター
フェイスに spool2html.pl というのもあります。
.xref spool2html.pl


.S	HTML化する単位 (数 or 日)
.l	$HTML_INDEX_UNIT
.key	$HTML_INDEX_UNIT

	$HTML_INDEX_UNIT (default 'day') 

expireしない場合一つの htdocs/ に数千のファイルができることになり
かねません。これよりはファイル100個ごと、もしくは日ごとにdirectoryをま
とめておく方が見やすいでしょう。

現在の標準実装のデフォールトは $HTML_INDEX_UNIT = 'day'; で

	htdocs/19960916/index.html
	htdocs/19960916/記事番号.html
	…

のように 1996/09/16 日のMLの記事を htdocs/19960916/ 以下にHTML化
します。

また、
	$HTML_INDEX_UNIT = 数字 (e.g. 100)

とした場合記事100個ごとに別のdirectoryを作ります。
  
	htdocs/100/
	htdocs/200/
	…

.S	スレッド化した index.html を作成する
.k	$HTML_THREAD
.k	スレッド化したHTML階層を作る

スレッド化 HTML (libsynchtml.pl)

	$HTML_THREAD = 1; 

にするとスレッド化したindex.html としてthread.html を作ります。両方を
作るので好きな階層を見ればいいでしょう。
スレッドには In-Reply-To: と References: の依存関係を使っています。

よって、この場合は	 

	thread.html
	index.html
		SUB-DIRECTORY/thread.html
		SUB-DIRECTORY/index.html
	…

のように両方のファイルが作られ別の階層が形成されるので、見る人にはどっ
ちか好きな方をたどってみてもらえば良いでしょう。


.S	HTMLファイルのExpire
.k	$HTML_EXPIRE_LIMIT
.k	$HTML_EXPIRE

$HTML_EXPIRE_LIMIT	(default 0)
	expire の“日”数。もし０以下ならおこなわない。
	これが指定されていないときは index.html は増える一方:-)

＃注意: $HTML_EXPIRE はわかりにくいので $HTML_EXPIRE_LIMIT へ名前を変えた。
＃      なお内部では自動変換しているのでどっちでも動く

なお今のアルゴリズムは以下のようなものです。htdocs の下は

	thread.html
	index.html
		SUB-DIRECTORY/thread.html
		SUB-DIRECTORY/index.html
		SUB-DIRECTORY/100.html
		…

のような階層を成しています。今はファイル単位ではなく sub-directory ご
とに expire するか否かを決定しています。
そうしないと中途半端に記事が欠落するとか、中途半端にファイルがなくなっ
た状態で thread を再生成しなければならないので、ものすごく複雑な処理が
必要になるからです。

directory ごと expire する根拠はdirectory 中に含まれる全てのファイルが 
expire だと判定された場合です。よって、ある directory 中の一部のファイ
ルが expire の日付を過ぎていてもそれらは全てのファイルが expire される
まで残り続けることに注意して下さい。

なお directory ごと消す時に一番上の index.html thread.html は再構成さ
れます。


.S	BASE64の展開
.k	$BASE64_DECODE
.k	mewdecode

base64 で encode されたものがあった場合$BASE64_DECODE という変数に定義
された base64 decoder を使って展開しその結果をHTMLの中に埋め込みます。
なお展開した結果はFMLが勝手につけた名前でファイルに落されます。
ユーザが与えた名前は security 上使いません。

例：
	BASE64_DECODE = "/usr/local/bin/mewdecode";


.S	$HTML_OUTPUT_FILTER
.k	$HTML_OUTPUT_FILTER

index.html を作る時 $HTML_OUTPUT_FILTER というプログラムを通してから作
る。具体的には 日本語漢字変換やMIME,BASE64 decoder 等が該当するだろう。


.S	$HTML_TITLE_HOOK
.k	$HTML_TITLE_HOOK

HTMLに変換された記事をファイルに保存する直前に実行されるフック。

例：
	q#$HtmlTitle = sprintf("%s %s", $Now, $HtmlTitle);#;

で、タイトルのシンタックスを日付を付け加える等…変えられる。


.S	キーワードによるHTML化の自動分類 （今の実装でOKか未確認？）
.k	@HTML_FIELD
.k	Keyword:

ヘッダの Keyword: エントリが含んでいるキーワードが @HTML_FIELD のどれ
かにマッチした場合に、キーワード別に別のHTML階層を作ります。


.S	TalkWithHttpServer
.l	TalkWithHttpServer
.k	TalkWithHttpServer
.k	&TalkWithHttpServer
.xref	bin/geturl.pl

SYNOPSIS:
	&TalkWithHttpServer($host, $port, $request, $tp, *e); 

	$host		ホスト		(e.g. www.iij.ad.jp)
	$port		ポート番号	(70, 80, 21, ...)
	$request	リクエストの内容
	$tp		TYPE OF PROTOCOL (http, gopher, ftp, ...)
	*e		答えを入れるためのstab


http:// で始まらない時には、デフォールトで聞きにいくサーバを
	$DEFAULT_HTTP_SERVER
.k	$DEFAULT_HTTP_SERVER

で、またデフォールトを80から変えたい時は

	$DEFAULT_HTTP_PORT 
.k	$DEFAULT_HTTP_PORT 

で変更できます。同様に gopher についても

	$DEFAULT_GOPHER_SERVER
	$DEFAULT_GOPHER_PORT 
.k	$DEFAULT_GOPHER_SERVER
.k	$DEFAULT_GOPHER_PORT 

という変数が用意されています。

例：
    if ($tp =~ /http/i) {
	$host = $host || $DEFAULT_HTTP_SERVER;
	$port = $port || $DEFAULT_HTTP_PORT || 80;

	# connect http server
	&Mesg(*e, ">>> HREF=$tp://$host$request\n");
	&TalkWithHttpServer($host, $port, $request, $tp, *e); 
	&Mesg(*e, ">>> ENDS HREF=$tp://$host$request\n");
    } 
	

.S	URLの中身を返すサーバ
.k	&HRef
.k	libhref.pl

一番単純なやり方は

$START_HOOK = q#
    require 'libhref.pl';
    &HRef($Envelope{'Body'}, *Envelope);
    $DO_NOTHING =1;
#;

です。こうするとメール本文をコマンドレポートの形で送り返します。


.S	HRef関数によるURL先データの引き落とし
.l	HRef
.k	&HRef
.k	HRef

SYNOPSIS:
    &HRef($request, *Envelope);

$request のURLの内容を$Envelope{'message'}に入れて送り返す。
$request は

	http://
	gopher://
	ftp://

を理解します。ftp はローカル or ftpmailへのリレーへ自動的に切替えます。
また、もしバイナリデータの場合はuuencodeして送り返します。

関数の使い方の実例としては bin/geturl.pl 
.xref bin/geturl.pl


.# $Id$
.# Copyright (C) 1993-1997 Ken'ichi Fukamachi
.#          All rights reserved. 
.#               1993-1996 fukachan@phys.titech.ac.jp
.#               1996-1997 fukachan@sapporo.iij.ad.jp
.# 
.# FML is free software; you can redistribute it and/or modify
.# it under the terms of GNU General Public License.
.# See the file COPYING for more details.
