.# ##########################################################
.C	アーカイブ, Archive & Expire
.label	{archive}

場所をとるから古い記事にはgzipかけたい。でも一つ一つやるより100個ずつ
とかまとめて固めると、さらに効率が上がります。というのは、ヘッダとか同
じようなものが繰り返し出てくるからですね。


.S	古い記事に gzip をかけて固める(場所をとるから)
.key	@ARCHIVE_DIR
.key	@StoredSpool_DIR

config.ph の例：

	@ARCHIVE_DIR = ('var/archive');

＃ @StoredSpool_DIR = ('var/archive'); は Obsolete な書き方です。
＃ Backward Compatibility として
＃ 内部で @ARCHIVE_DIR に代入してるので、どちらでも動きます

以下記事100個ずつ、つまり

	spool/1〜100

を tar して gzip かけて

	var/archive/100.tar.gz 

と作っているとしましょう

これを 次のように fml.pl は解釈します。
上に出てくる 100 個という数字は

	$DEFAULT_ARCHIVE_UNIT
.k	$DEFAULT_ARCHIVE_UNIT

でコントロールできます。デフォールトは 100 です。


.S	"# get 1 " と archive

例えば、"# get 1 " というコマンドを送り込んだ時

	ml-dir/spool/	

を探索し、

	もしファイル spool/1 が見つかればＯＫ、
	見つからない時は

	ml-dir/var/archive/	

という場所も探し、1-100 までがtar + gzipされている 

	var/archive/100.tar.gz 

があれば、ファイル １ を取り出して１だけを送り返す。


.S	"# mget 1 " と archive

上と同じです。


.S	"# mget 1-10 " と archive

これも同様で、もし見つからない時はアーカイブ(100.tar.gz)から1〜10
の記事を取り出してその10個だけを送り返します。


.S	"# get 100.tar.gz" と archive

これは "# mget 100.tar.gz" と再解釈され

	var/archive/100.tar.gz 

を送り返します。デフォールトはこれを uuencode したものです


.S	"# mget 100.tar.gz" と archive

上述のようになります。


.S	Archive.pl (bin/Archive.pl)
.k	bin/Archive.pl
.key	Archive.pl

	Archive.pl [-dh] [-A ARCHIVE_DIR][-u unit] MAX
	-d	debug mode
	-h	help 
	-A	アーカイブを作る場所を指定
		config.ph より強い
	-u	固める単位。デフォールトは記事１００個ずつ

	MAX	これで最大どの記事までをアーカイブするか強制指定
		デフォールトでは今の記事番号の直前の”１００の倍数”
		までをアーカイブの対象の記事としてアーカイブを作る。

注意：このプログラムはＭＬのホームで実行されることを前提にしています。
よって、

	chdir /var/spool/ml/Elena; perl bin/Archive.pl 

のように使うことを期待されています。
		

.S	gzip file にする(アーカイブへの変換)
.key	Archive.pl

それには上述の Archive.pl というのを使って下さい。
さらに cron で自動処理するなら次の節を御覧下さい

これは Archive.pl 2000 とかすると、2000 までのファイルを 100 個ずつの
塊にして、archiveに作ります。変数は Archive.pl の先頭でセットしてくだ
さい。スプールのオリジナルは消さないので、注意を払って消して下さい
(とりかえしがききませんから、それは)
＃自分じゃ、念のため ある程度まとまったところでこうやって手動でつくっ
＃てます。

例えば、

	spool/1-100	を tar+gzip して var/archive/100.tar.gz
	spool/101-200	を tar+gzip して var/archive/200.tar.gz

のようなファイルをarchiveの下に作るプログラムが bin/Archive.pl です。

目的のＭＬの場所にまでいって

% ls 

MSendrc		actives		config.ph	deny
guide		help		list		log
members		objective	seq		spool
summary		welcome

% test -d var || mkdir var
% test -d var/archive || mkdir var/archive

% perl Archive.pl 3800

	…たくさんメッセージが出るが省略…

% ls archive

100.tar.gz   200.tar.gz 
	…たくさんメッセージが出るが省略…


spoolの 3800 までの 100 個ずつのパッケージを作りました。spoolの方の元
メールを自動的に消しはしない(安全のため)ので、自分で消して下さい。


.S	アーカイブ作成を cron で自動処理
.key	Archive.sh
.key	Archive.pl
.key	crontab

cronで自動的（例えば週一日曜の朝とか）に次の形で

   (chdir "MLサーバのdirectory名"; /usr/local/bin/perl bin/Archive.pl)

とでもすれば良いでしょう。
＃見本として bin/Archive.sh があるので見てみてね。

 いくつかＭＬがあるなら、シェルスクリプトにまとめて呼べば楽ですね。
ようするに まとめ送りと一緒とかでもよいですね

例：
crontab が
例：

	0 * * * * /bin/sh /usr/libexec/fml/archive.sh


/usr/libexec/fml/archive.sh は
例：
	#!/bin/sh

	(chdir /var/spool/ml/Elena;    /usr/local/bin/perl bin/Archive.pl)
	(chdir /var/spool/ml/Freekick; /usr/local/bin/perl bin/Archive.pl)



.S	何故、まとめてgzip化したいのか？

１．一個一個gzipかけると、約半分にしかなりませんが、１００個まとめて書
けると、ヘッダとかの重なりがあるので約２５％にまで圧縮できるようになり
ます。

２．Mail-Countが万を越える頃になるとi-nodeの計算に時間がかかるようにな
るのでファイル数を減らす or ほかの場所に移すことに意味があるようになり
ます。そこでspoolの中身をうつし、１００分の一のファイル数にすると効果
が非常にあります。


.# $Id$
.# Copyright (C) 1993-1996 fukachan@phys.titech.ac.jp
.# Copyright (C) 1996-1997 fukachan@sapporo.iij.ad.jp
.# fml is free software distributed under the terms of the GNU General
.# Public License. see the file COPYING for more details.
